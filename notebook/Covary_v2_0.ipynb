{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xo5neBB0Xebq",
        "cEidqXg1Yvdr",
        "omOIq02EY49k",
        "B8rV8_HqZJof",
        "hZrUhl_9ZNlk"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://assets.zyrosite.com/d9510y2R1JHwG05k/covary-1-dWxO42PGWjI8Kp03.png\" height=\"200\" align=\"right\" style=\"height:340px\">\n",
        "\n",
        "#Covary v2.0: Deep learning-based phylogenetic reconstruction using [TIPs-VF](https://www.biorxiv.org/content/10.1101/2025.02.15.637782v1)\n",
        "\n",
        "Covary is a deep learning framework for phylogenetic reconstruction that leverages the TIPs-VF genetic representation. TIPs-VF belongs to the Translator-Interpreter Pre-seeding (TIPs) family, a set of encoding schemes designed to enhance the numerical representation of genetic sequences for machine learning applications. By integrating Keras-based neural network architectures, Covary provides an efficient and scalable approach to reconstructing phylogenetic trees.\n",
        "\n",
        "---\n",
        "\n",
        "**Versions:**\n",
        "\n",
        "*Public release*\n",
        "* [2.1](https://colab.research.google.com/drive/1wZ0hmDZzAlQkHALUbrN0txkUVCJssReZ?usp=sharing) – Adds user-defined plot customization and introduces filtering of sequence entries containing invalid characters, enabling faster and more reliable project implementation.\n",
        "* [2.0](https://colab.research.google.com/drive/1_DyU37rW-YZ8sxUP_BhnoUYFjiv1NNK0?usp=sharing) – Introduces codon normalization, resolving inconsistencies in the relationship between input sequences and open reading frames or protein translations within unaligned datasets.\n",
        "\n",
        "*Pre-release*\n",
        "* [1.3](https://colab.research.google.com/drive/1y9-0pyWNG5SlAUieGp7-ZSfQ3qN6E7VB?usp=sharing) – Optimizes the perplexity parameter for t-SNE, enabling reliable analysis of datasets with limited sample sizes.\n",
        "* [1.2](https://colab.research.google.com/drive/1jwwN_OKAspYaYjDoyoYfivoGf_QF1kHY?usp=sharing) – Reduces sequence ambiguity, improving support for datasets containing unprocessed or ambiguous genetic sequences.\n",
        "*   [1.1](https://colab.research.google.com/drive/1EkTk7vaBUqCiQFkH1LtK5RfjQW7p0i2D?usp=sharing) – Enhances memory efficiency to prevent session crashes caused by RAM overload.\n",
        "*   [1.0](https://colab.research.google.com/drive/14DHrXhgHjL7ieUILnlpl1mzqo6rFY7C4?usp=sharing) – Initial release (unsupported)"
      ],
      "metadata": {
        "id": "IFj0ktv9S5Ek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prepare your sequence data, then hit `Runtime` -> `Run all`\n",
        "Fields marked with ⚠️ may require your attention or input, please don't collapse them while running Covary"
      ],
      "metadata": {
        "id": "iUjtMngPWYXi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1. ⚠️ Upload your data"
      ],
      "metadata": {
        "id": "NH9BcyNkW0Ou"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUuj0X_DSQQT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "filename = list(uploaded.keys())[0]\n",
        "var_name = \"input_seq.fasta\"\n",
        "os.rename(filename, var_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 2. Install dependencies"
      ],
      "metadata": {
        "id": "xo5neBB0Xebq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This will install the ff packages/modules\n",
        "import os\n",
        "import sys\n",
        "import re\n",
        "import math\n",
        "from itertools import product\n",
        "!pip install umap-learn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import umap\n",
        "from tensorflow.keras import layers, models\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram\n",
        "import seaborn as sns\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "import zipfile\n",
        "from datetime import datetime\n",
        "import sys, builtins"
      ],
      "metadata": {
        "id": "7pHQTn-DXjqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 3. QC Check"
      ],
      "metadata": {
        "id": "cEidqXg1Yvdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-process the data with whitespace remover + 'clean_seq.py' from https://github.com/mahvin92/TIPs-VF/blob/main/pre-processing/clean_seq.py\n",
        "\n",
        "def replace_non_atcg_remove_whitespace(file_name, wrap_width=None):\n",
        "    def wrap_seq(seq, width):\n",
        "        return [seq[i:i+width] for i in range(0, len(seq), width)]\n",
        "\n",
        "    with open(file_name, 'r') as fh:\n",
        "        lines = fh.readlines()\n",
        "\n",
        "    with open(file_name, 'w') as fh:\n",
        "        for line in lines:\n",
        "            if line.startswith('>'):\n",
        "                fh.write(line.rstrip() + '\\n')\n",
        "            else:\n",
        "                # Remove ALL whitespace (including internal spaces/tabs/newlines),\n",
        "                # then uppercase.\n",
        "                seq = re.sub(r'\\s+', '', line)\n",
        "                seq = seq.upper()\n",
        "\n",
        "                if seq == '':\n",
        "                    continue\n",
        "\n",
        "                # Replace non-ATCG with 'N'\n",
        "                cleaned = ''.join([ch if ch in 'ATCG' else 'N' for ch in seq])\n",
        "\n",
        "                if wrap_width and isinstance(wrap_width, int) and wrap_width > 0:\n",
        "                    for chunk in wrap_seq(cleaned, wrap_width):\n",
        "                        fh.write(chunk + '\\n')\n",
        "                else:\n",
        "                    fh.write(cleaned + '\\n')\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Run\n",
        "# -----------------------------\n",
        "file_name = \"input_seq.fasta\"\n",
        "replace_non_atcg_remove_whitespace(file_name, wrap_width=60)  # change value to set wrap number"
      ],
      "metadata": {
        "id": "-t_ZXDnvIAlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 4. Covary encoding"
      ],
      "metadata": {
        "id": "omOIq02EY49k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone Covary-encoder\n",
        "!git clone https://github.com/mahvin92/Covary-encoder.git\n",
        "%cd Covary-encoder\n",
        "!git sparse-checkout init --cone\n",
        "!git sparse-checkout set Active README.md\n",
        "\n",
        "# Reconstruct runtime\n",
        "%cd Active\n",
        "os.mkdir(\"codeenigma_runtime\")\n",
        "!mv /content/Covary-encoder/Active/__init__.py /content/Covary-encoder/Active/codeenigma_runtime\n",
        "!mv /content/input_seq.fasta /content/Covary-encoder/\n",
        "print(\"Your input file has been moved to the Covary-encoder directory for encoding\")\n",
        "%cd /content/Covary-encoder/\n",
        "!pip install /content/Covary-encoder/Active/codeenigma_runtime-*.whl"
      ],
      "metadata": {
        "id": "5N7txJKc04N6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 5. Data extraction ⚠️"
      ],
      "metadata": {
        "id": "qT2mBSUU05O5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Covary-encoder\n",
        "sys.path.append(\"/content/Covary-encoder/Active\")\n",
        "builtins.exit = sys.exit\n",
        "import Covary_encoder"
      ],
      "metadata": {
        "id": "9tpHt-I6ZIy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 6. Deep learning"
      ],
      "metadata": {
        "id": "B8rV8_HqZJof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start DL by Load dataset\n",
        "file_path = \"seq_TIPs-encoded.tsv\" # This can be downloaded from the file path directory\n",
        "data = pd.read_csv(file_path, sep='\\t')\n",
        "\n",
        "print(data.head())\n",
        "\n",
        "# Extract features\n",
        "def process_column(col):\n",
        "    return np.array([float(x) for x in col.split(',')])\n",
        "\n",
        "# Parse all cos_sim and theta columns\n",
        "X_cos_sim_1 = data['cos_sim_1'].apply(process_column)\n",
        "X_cos_sim_2 = data['cos_sim_2'].apply(process_column)\n",
        "X_cos_sim_3 = data['cos_sim_3'].apply(process_column)\n",
        "\n",
        "X_theta_s_1 = data['theta_s_1'].apply(process_column)\n",
        "X_theta_s_2 = data['theta_s_2'].apply(process_column)\n",
        "X_theta_s_3 = data['theta_s_3'].apply(process_column)\n",
        "\n",
        "# Compute averages index-wise\n",
        "X_avg_cos_sim = [\n",
        "    (x1 + x2 + x3) / 3.0\n",
        "    for x1, x2, x3 in zip(X_cos_sim_1, X_cos_sim_2, X_cos_sim_3)\n",
        "]\n",
        "\n",
        "X_avg_theta = [\n",
        "    (t1 + t2 + t3) / 3.0\n",
        "    for t1, t2, t3 in zip(X_theta_s_1, X_theta_s_2, X_theta_s_3)\n",
        "]\n",
        "\n",
        "# Final combined feature vector\n",
        "X_combined = np.array([\n",
        "    np.concatenate([avg_cos, avg_theta])\n",
        "    for avg_cos, avg_theta in zip(X_avg_cos_sim, X_avg_theta)\n",
        "])\n",
        "\n",
        "print(f\"Shape of the data: {X_combined.shape}\")\n",
        "\n",
        "# Data scaling\n",
        "X_scaled = StandardScaler().fit_transform(X_combined)\n",
        "\n",
        "# Get the labels (assuming it's available)\n",
        "labels = data['Gene_name']  # Replace with your actual label column name\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Build the Autoencoder-like Neural Network model\n",
        "def build_autoencoder(input_dim, embedding_dim=10):\n",
        "    encoder_input = layers.Input(shape=(input_dim,))  # Define input shape explicitly\n",
        "    x = layers.Dense(128, activation='relu')(encoder_input)\n",
        "    x = layers.Dense(64, activation='relu')(x)\n",
        "    encoded = layers.Dense(embedding_dim, activation='linear')(x)  # Embedding layer output dimension\n",
        "\n",
        "    x = layers.Dense(64, activation='relu')(encoded)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    decoded = layers.Dense(input_dim, activation='linear')(x)  # Reconstructing to input_dim\n",
        "\n",
        "    # Autoencoder (encoder + decoder)\n",
        "    autoencoder = models.Model(encoder_input, decoded)\n",
        "\n",
        "    return autoencoder\n",
        "\n",
        "# Initialize the model\n",
        "autoencoder_model = build_autoencoder(X_scaled.shape[1], embedding_dim=10)\n",
        "\n",
        "# Compile the model with Mean Squared Error loss for reconstruction\n",
        "autoencoder_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Train the model on the input data to learn the embedding representation\n",
        "autoencoder_model.fit(X_scaled, X_scaled, epochs=50, batch_size=32, verbose=1)\n",
        "\n",
        "# Extract the embeddings (output of the encoder)\n",
        "encoder = models.Model(inputs=autoencoder_model.input, outputs=autoencoder_model.layers[3].output)\n",
        "embeddings = encoder.predict(X_scaled)"
      ],
      "metadata": {
        "id": "w-WnUYNTZNTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 7. Scoring and analysis"
      ],
      "metadata": {
        "id": "hZrUhl_9ZNlk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get vector embeddings for:\n",
        "# PCA\n",
        "pca = PCA(n_components=2)\n",
        "pca_result = pca.fit_transform(embeddings)\n",
        "\n",
        "# t-SNE\n",
        "n_samples = embeddings.shape[0]\n",
        "safe_perplexity = max(2, min(30, (n_samples - 1) // 2))  # auto-adjust\n",
        "tsne = TSNE(n_components=2, random_state=42, perplexity=safe_perplexity)\n",
        "tsne_result = tsne.fit_transform(embeddings)\n",
        "\n",
        "# UMAP\n",
        "umap_model = umap.UMAP(n_components=2, random_state=42)\n",
        "umap_result = umap_model.fit_transform(embeddings)"
      ],
      "metadata": {
        "id": "e1Qiuzwk1oAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make results directory\n",
        "%cd /content/\n",
        "os.makedirs(\"covary_results\", exist_ok=True)\n",
        "cool_warm = plt.cm.coolwarm\n",
        "cool = plt.cm.cool\n",
        "warm = plt.cm.autumn\n",
        "\n",
        "# -----------------------------\n",
        "# Helpers\n",
        "# -----------------------------\n",
        "def save_plot(fig, filename):\n",
        "    fig.savefig(f\"covary_results/{filename}\", dpi=300, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "\n",
        "def save_embeddings(embeddings, filename, labels=None):\n",
        "    \"\"\"Save embeddings with headers and optional row labels.\"\"\"\n",
        "    df = pd.DataFrame(embeddings, columns=[f\"Dim{i+1}\" for i in range(embeddings.shape[1])])\n",
        "    if labels is not None:\n",
        "        df.insert(0, \"Label\", labels)\n",
        "    df.to_csv(f\"covary_results/{filename}\", sep=\"\\t\", index_label=\"Sample\")\n",
        "\n",
        "def save_distances(distances, filename):\n",
        "    \"\"\"Save pairwise distance matrix with row/col headers.\"\"\"\n",
        "    n = distances.shape[0]\n",
        "    labels = [f\"Sample{i+1}\" for i in range(n)]\n",
        "    df = pd.DataFrame(distances, index=labels, columns=labels)\n",
        "    df.to_csv(f\"covary_results/{filename}\", sep=\"\\t\")\n",
        "\n",
        "def save_linkage(linkage_matrix, filename):\n",
        "    \"\"\"Save linkage matrix with informative headers.\"\"\"\n",
        "    df = pd.DataFrame(linkage_matrix,\n",
        "                      columns=[\"Cluster1\", \"Cluster2\", \"Distance\", \"SampleCount\"])\n",
        "    df.to_csv(f\"covary_results/{filename}\", sep=\"\\t\", index=False)\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Embedding plots\n",
        "# -----------------------------\n",
        "def plot_embeddings_and_save(embeddings, encoded_labels, gene_names, title, fname):\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
        "    scatter = ax.scatter(embeddings[:, 0], embeddings[:, 1],\n",
        "                         c=encoded_labels, cmap=plt.cm.coolwarm, alpha=0.5, s=100)\n",
        "    ax.set_title(title)\n",
        "\n",
        "    for i, gene_name in enumerate(gene_names):\n",
        "        ax.annotate(\n",
        "            gene_name,\n",
        "            xy=(embeddings[i, 0], embeddings[i, 1]),\n",
        "            xytext=(5, 5),\n",
        "            textcoords='offset points',\n",
        "            fontsize=5,\n",
        "            color='black',\n",
        "            alpha=0,       # adjust transparency (0 = fully transparent, 1 = fully opaque)\n",
        "            arrowprops=dict(arrowstyle='-', lw=0.5, color='gray', alpha=0) # arrows also semi-transparent\n",
        "        )\n",
        "\n",
        "    plt.colorbar(scatter, ax=ax, label='Sequence entry/group')\n",
        "    save_plot(fig, fname)\n",
        "\n",
        "# Save embeddings arrays with headers\n",
        "save_embeddings(pca_result, \"pca_embeddings.tsv\", labels=labels)\n",
        "save_embeddings(tsne_result, \"tsne_embeddings.tsv\", labels=labels)\n",
        "save_embeddings(umap_result, \"umap_embeddings.tsv\", labels=labels)\n",
        "\n",
        "plot_embeddings_and_save(pca_result, encoded_labels, labels.tolist(), \"PCA Embeddings\", \"pca_embeddings.png\")\n",
        "plot_embeddings_and_save(tsne_result, encoded_labels, labels.tolist(), \"t-SNE Embeddings\", \"tsne_embeddings.png\")\n",
        "plot_embeddings_and_save(umap_result, encoded_labels, labels.tolist(), \"UMAP Embeddings\", \"umap_embeddings.png\")\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Pairwise distances\n",
        "# -----------------------------\n",
        "def plot_heatmap_and_save(matrix, title, fname, gene_names):\n",
        "    \"\"\"Plot heatmap with gene names on both axes.\"\"\"\n",
        "    fig = plt.figure(figsize=(25, 20))\n",
        "    sns.heatmap(matrix, cmap=plt.cm.coolwarm, cbar=True,\n",
        "                xticklabels=gene_names, yticklabels=gene_names)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Sample ID')\n",
        "    plt.ylabel('Sample ID')\n",
        "    save_plot(fig, fname)\n",
        "\n",
        "pca_distances = squareform(pdist(pca_result, metric='euclidean'))\n",
        "umap_distances = squareform(pdist(umap_result, metric='euclidean'))\n",
        "tsne_distances = squareform(pdist(tsne_result, metric='euclidean'))\n",
        "\n",
        "save_distances(pca_distances, \"pca_distances.tsv\")\n",
        "save_distances(umap_distances, \"umap_distances.tsv\")\n",
        "save_distances(tsne_distances, \"tsne_distances.tsv\")\n",
        "\n",
        "plot_heatmap_and_save(pca_distances, \"Heatmap of PCA Embedding Distances\", \"pca_heatmap.png\", labels.tolist())\n",
        "plot_heatmap_and_save(umap_distances, \"Heatmap of UMAP Embedding Distances\", \"umap_heatmap.png\", labels.tolist())\n",
        "plot_heatmap_and_save(tsne_distances, \"Heatmap of t-SNE Embedding Distances\", \"tsne_heatmap.png\", labels.tolist())\n",
        "\n",
        "# -----------------------------\n",
        "# 3. Dendrograms\n",
        "# -----------------------------\n",
        "def plot_dendrogram_and_save(embeddings, method, title, fname, gene_names):\n",
        "\n",
        "    fig = plt.figure(figsize=(25, 50))\n",
        "    linkage_matrix = linkage(embeddings, method=method)\n",
        "    dendrogram(linkage_matrix,\n",
        "               leaf_rotation=0,\n",
        "               leaf_font_size=5,\n",
        "               orientation=\"left\",\n",
        "               labels=gene_names)\n",
        "    plt.title(title)\n",
        "    plt.ylabel('Sample ID')\n",
        "    plt.xlabel('Distance')\n",
        "    save_plot(fig, fname)\n",
        "    save_linkage(linkage_matrix, fname.replace(\".png\", \".tsv\"))\n",
        "\n",
        "methods = [\"ward\", \"complete\", \"average\", \"single\"]\n",
        "\n",
        "for method in methods:\n",
        "    plot_dendrogram_and_save(pca_result, method,\n",
        "                             f\"PCA Dendrogram ({method})\",\n",
        "                             f\"pca_dendrogram_{method}.png\",\n",
        "                             labels.tolist())\n",
        "    plot_dendrogram_and_save(umap_result, method,\n",
        "                             f\"UMAP Dendrogram ({method})\",\n",
        "                             f\"umap_dendrogram_{method}.png\",\n",
        "                             labels.tolist())\n",
        "    plot_dendrogram_and_save(tsne_result, method,\n",
        "                             f\"t-SNE Dendrogram ({method})\",\n",
        "                             f\"tsne_dendrogram_{method}.png\",\n",
        "                             labels.tolist())\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 4. Zip and download results\n",
        "# -----------------------------\n",
        "date_str = datetime.now().strftime(\"%Y%m%d\")\n",
        "zip_filename = f\"Covary results_{date_str}.zip\"\n",
        "\n",
        "with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "    for root, dirs, files_in_dir in os.walk(\"covary_results\"):\n",
        "        for file in files_in_dir:\n",
        "            # keep only .png and .tsv (but exclude the heavy seq_TIPs-encoded.tsv if it exists)\n",
        "            if file.endswith(\".png\") or (file.endswith(\".tsv\") and \"seq_TIPs-encoded\" not in file):\n",
        "                file_path = os.path.join(root, file)\n",
        "                zipf.write(file_path, os.path.relpath(file_path, \"covary_results\"))"
      ],
      "metadata": {
        "id": "38MjgSZtxYgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 8. ⚠️ Download results"
      ],
      "metadata": {
        "id": "Tb5qZwqvGJMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(zip_filename)\n",
        "print(\"Covary has finished running\")"
      ],
      "metadata": {
        "id": "3vJ3syKyGUqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Instructions"
      ],
      "metadata": {
        "id": "UR-9etBtZlcb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quick start**\n",
        "\n",
        "1. Press ```\"Runtime\" -> \"Run all\".```\n",
        "2. Upload your FASTA-formatted genetic sequence(s) in **Step 1** (recommended file types: .txt or .fasta).\n",
        "3. Fields marked with ⚠️ may require your attention or input. Do not collapse these fields while running Covary.\n",
        "4. The pipeline consists of 8 steps. The currently running step is indicated by a spinning circle with a stop sign.\n",
        "\n",
        "\n",
        "**Best Practices**\n",
        "\n",
        "* Ensure that all sequences cover the same genomic region. For example, in taxonomic analysis using bacterial 16S rRNA, if one entry begins at base position TSS +1, all other 16S rRNA sequences should also start at or close to that position.\n",
        "\n",
        "* Before interpreting dendrograms, first inspect the generated vector embeddings. Evaluate clustering results and determine which dimensionality reduction method provides the clearest resolution of relationships between your sequences. Examine pairwise distances of the vector embeddings when necessary.\n",
        "\n",
        "* Based on the chosen reduction method, identify which linkage method (Ward, Average, Complete, Single) provides the best subgrouping of your data points.\n",
        "\n",
        "\n",
        "**Sequence representtion**\n",
        "\n",
        "Name your file as ```input_seq.fasta```, a critical requirement for representation. Input genetic sequences are represented using [TIPs-VF](https://doi.org/10.1101/2025.02.15.637782) and processed by a deep learning model built on Keras. The resulting TIPs-encoded sequences can be downloaded from the file browser as ```seq_TIPs-encoded.tsv```. Vector embeddings generated by PCA, t-SNE, and UMAP are automatically included in the zipped results (in TSV format).\n",
        "\n",
        "\n",
        "**Phylogenetic reconstruction**\n",
        "\n",
        "Covary applies multiple linkage methods (Ward, Average, Complete, Single) to infer and compare relationships among the represented input sequences. Deep learning enables recognition of unique patterns and resolution of sequence differences. A phylogenetic tree (without branch length) is reconstructed and inferred based on denodrogram clustering (similar to a cladogram-type visualization).\n",
        "\n",
        "\n",
        "**Result zip file contents**\n",
        "\n",
        "1. **Vector embeddings**: Numerical data in ```.tsv``` format for PCA, t-SNE, and UMAP.\n",
        "2. **Vector embedding plots**: Scatter plots of Dim-1 *vs.* Dim-2, labeled by sequence entry. A color gradient (z-score) standardizes sequence indices regardless of dataset size.\n",
        "3. **Heatmap (pairwise distance plot)**: Euclidean pairwise distance plots, provided alongside each reduction analysis.\n",
        "4. **Dendrogram linkages**: Numerical data in ```.tsv``` format for linkage analyses (Ward, Average, Complete, Single) across PCA, t-SNE, and UMAP.\n",
        "5. **Dendrogram plots**: Visualizations showing distances (x-axis) and sequence indices (y-axis) across different linkage methods and reduction analyses.\n",
        "\n",
        "\n",
        "**Troubleshooting**\n",
        "\n",
        "* Check that the runtime type is set to GPU at ```\"Runtime\" -> \"Change runtime type\"```.\n",
        "* Try to restart the session ```\"Runtime\" -> \"Factory reset runtime\"```.\n",
        "* Check your input sequence for the presence of invalid sequence characters or white spaces. Note that Covary_encoder can only represent A, T, C, G, N sequences to reduce ambiguity factors that may influence the deep learning results. Limit the use of non-conventional DNA sequences, as much as possible, and resolve sequence data using a reference assembly. *Newer versions of Covary (e.g., v.2.0 and above) have added QC check step that removes whitespaces and filter param that is set to ignore/remove data/sequence entry containing invalid sequences prior to representation; ```see Steps 1 and 3```)*\n",
        "* Pre-process your data, when needed. Most problems with non-ATCGN in Covary_encoder can be fixed by running your data first in the 'clean_seq.py' that can be downloaded from TIPs-VF [GitHub](https://github.com/mahvin92/TIPs-VF/tree/main/pre-processing). *Newer versions of Covary (e.g., v.2.0 and above) have incorporated this workflow; ```see Steps 1 and 3```)*\n",
        "* If download failed to start, rerun ```Step 8```.\n",
        "\n",
        "\n",
        "**Bug**\n",
        "\n",
        "If you encounter any bugs, please open a ticket [here](https://github.com/mahvin92/Covary/issues/new) or request a support [here](https://covary.chordexbio.com).\n",
        "\n",
        "**Usage**\n",
        "\n",
        "Covary can be applied to a variety of studies [see performance validations](https://covary.chordexbio.com):\n",
        "1. Clade or strain reconstruction in viral infections\n",
        "2. Taxonomic species evolution\n",
        "3. Clonal and driver mutation tracking in tumor evolution\n",
        "4. Genetic relationship and divergence studies\n",
        "\n",
        "**Funding**\n",
        "\n",
        "```None```\n",
        "\n",
        "\n",
        "**License**\n",
        "\n",
        "[Read here](https://github.com/mahvin92/Covary/blob/main/LICENSE)\n",
        "\n",
        "**Footnote**\n",
        "\n",
        "Covary is powered by [TIPs](https://tips.chordexbio.com/) and [ChordexBio](https://chordexbio.com/), made with Python, and tested using Google Colab ❤️"
      ],
      "metadata": {
        "id": "ouQh02ggZwmK"
      }
    }
  ]
}